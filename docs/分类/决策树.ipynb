{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae968ff7",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "\n",
    "假设我们有一个数据集包含鸢尾花的特征（萼片长度、萼片宽度、花瓣长度和花瓣宽度）以及对应的类别（Setosa、Versicolor、Virginica）。最简单的决策树就是个if-else-then的分支。例如对鸢尾花数据分类可以这样做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd11abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 prediction: setosa\n",
      "Sample 2 prediction: virginica\n",
      "Sample 3 prediction: setosa\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(features):\n",
    "    # 决策树的判定条件和结果\n",
    "    if features[2] <= 2.45:\n",
    "        return 'setosa'\n",
    "    elif features[3] <= 1.75:\n",
    "        if features[2] <= 4.95:\n",
    "            if features[3] <= 1.65:\n",
    "                return 'versicolor'\n",
    "            else:\n",
    "                return 'virginica'\n",
    "        else:\n",
    "            if features[3] <= 1.55:\n",
    "                return 'virginica'\n",
    "            else:\n",
    "                return 'versicolor'\n",
    "    else:\n",
    "        return 'virginica'\n",
    "\n",
    "# 测试样例\n",
    "X_test = np.array([[5.1, 3.5, 1.4, 0.2],\n",
    "                   [6.3, 2.9, 5.6, 1.8],\n",
    "                   [4.9, 3.0, 1.4, 0.2]])\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    prediction = predict(X_test[i])\n",
    "    print(\"Sample\", i+1, \"prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd8538",
   "metadata": {},
   "source": [
    "## 决策树算法流程\n",
    "\n",
    "将这个经验法则通过数学和算法的方式来自动化处理，就衍生了很多决策树算法。以鸢尾花分类为例，这些算法基本上是这样的过程：\n",
    "\n",
    "\n",
    "* 特征选择：从训练数据集中选择最优特征作为当前节点的划分特征。通常使用某种准则（如信息增益、基尼指数或信息增益比）来评估特征的重要性。\n",
    "\n",
    "![](../../images/dicision-tree/dicision-tree-label.png)\n",
    "\n",
    "![](../../images/dicision-tree/dicision-tree-feature.png)\n",
    "\n",
    "* 树节点划分：根据选择的特征将训练数据集划分成子集。对于分类问题，每个子集对应于一个特征值或特征值范围；对于回归问题，则根据特征的阈值进行划分。\n",
    "\n",
    "![](../../images/dicision-tree/dicision-tree.png)\n",
    "\n",
    "* 递归构建子树：对每个子集递归地应用上述步骤，构建决策树的子树。如果子集中的样本属于同一类别（或具有相似的回归值），则停止划分。\n",
    "\n",
    "* 剪枝：对生成的决策树进行剪枝操作，以减小过拟合风险。剪枝方法可以是预剪枝（在构建树时提前停止划分）或后剪枝（在完整构建树之后剪掉部分叶节点）。\n",
    "\n",
    "* 终止条件：根据停止条件，确定是否继续构建子树。常见的停止条件包括达到最大深度、样本数量不足或没有更多特征可用。\n",
    "\n",
    "* 输出决策树：得到最终的决策树模型，可以将其用于预测新的输入数据。\n",
    "\n",
    "对于集成学习算法（如随机森林和GBDT），会有一些额外步骤：\n",
    "\n",
    "* 集成学习：对多个决策树进行集成。对于随机森林，每个决策树通过自助采样从原始训练数据集中获得；对于GBDT，每个决策树都是基于前一棵树的残差进行训练。\n",
    "\n",
    "* 预测结果：对于分类问题，通过投票或多数表决来确定最终的类别；对于回归问题，则取平均或加权平均作为最终的预测值。\n",
    "\n",
    "\n",
    "## 常见决策树算法\n",
    "\n",
    "以下是一些常见的决策树算法：\n",
    "\n",
    "* ID3（Iterative Dichotomiser 3）：使用信息增益作为特征选择准则来构建决策树。适用于离散型特征和多类别问题。\n",
    "\n",
    "* C4.5：C4.5是ID3算法的改进版，使用信息增益比作为特征选择准则。能够处理缺失值，并具有更好的鲁棒性。\n",
    "\n",
    "* CART（Classification and Regression Trees）：通用的决策树算法，可以处理分类和回归问题。使用基尼系数作为特征选择准则，在每个节点上生成二叉树结构。\n",
    "\n",
    "* CHAID（Chi-squared Automatic Interaction Detection）：一种基于卡方检验的决策树算法，适用于分类问题。能够处理离散型和连续型特征，并支持多类别问题。\n",
    "\n",
    "* MARS（Multivariate Adaptive Regression Splines）：基于样条函数的非参数回归方法，通过构建多个分段线性的子模型构建决策树。适用于回归和分类任务。\n",
    "\n",
    "* Random Forest（随机森林）：一种集成学习算法，基于决策树构建多个决策树，并通过投票或平均预测结果来做出最终的分类或回归决策。具有鲁棒性和泛化能力。\n",
    "\n",
    "* GBDT（Gradient Boosting Decision Trees）：一种梯度提升决策树算法，通过连续训练多个决策树来提高预测性能。每棵树都是基于前一棵树的残差进行训练。\n",
    "\n",
    "* XGBoost（eXtreme Gradient Boosting）：一种梯度提升决策树算法，结合了梯度提升和正则化技术，具有较高的准确性和泛化能力。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a536541",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
