{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f743a36",
   "metadata": {},
   "source": [
    "\n",
    "## 贝叶斯回归\n",
    "贝叶斯回归是一种基于贝叶斯统计推断的回归方法。它通过引入先验分布来表达对参数的不确定性，并利用观测数据来更新参数的后验分布。假设我们有一个训练集包含N个样本，每个样本由输入特征X和对应的输出标签y组成。具体步骤如下：\n",
    "\n",
    "* 参数建模，定义先验分布：选择适当的先验分布来表示参数的先验知识或假设。\n",
    "\n",
    "    * 建立参数 $w$ 的先验分布：$p(w)$。通常选择高斯分布作为w的先验，即 $p(w) = N(w|0, Σ0)$，其中 $0$ 是均值向量，$Σ0$ 是协方差矩阵。\n",
    "    * 建立输出标签y的条件分布：$p(y|X, w)$。通常假设 $y$ 服从高斯分布，即 $p(y|X, w) = N(y|Xw, σ^2I)$，其中 $σ^2$ 是噪声方差，$I$ 是单位矩阵。\n",
    "\n",
    "* 后验推断，计算后验分布：根据观测数据和先验分布，使用贝叶斯定理计算参数的后验分布。\n",
    "\n",
    "    * 根据贝叶斯定理计算参数的后验分布：$p(w|X, y) ∝ p(y|X, w) * p(w)$\n",
    "\n",
    "* 参数估计和预测，推断和预测：利用后验分布进行参数估计和预测。可以使用后验分布的均值、中位数等作为点估计，还可以计算预测分布来预测新数据。\n",
    "\n",
    "    * 参数估计：根据后验分布，可以获得参数w的点估计，如后验均值或最大后验估计（MAP）。\n",
    "    * 预测：通过获取参数w的后验分布，可以计算新数据点的预测分布，即 p(y*|x*, X, y) = ∫ p(y*|x*, w) * p(w|X, y) dw。这里，y表示预测的输出标签，x表示新的输入特征。\n",
    "\n",
    "贝叶斯回归提供了全面的概率建模方式，能够量化参数的不确定性，并灵活地引入先验知识。它对小样本、高噪声数据以及需要考虑模型不确定性的情况特别有帮助。\n",
    "\n",
    "在实际应用中，可以使用MCMC、变分推断、近似推断等技术来近似或采样后验分布。\n",
    "\n",
    "下面是使用Python和PyMC3库实现贝叶斯线性回归的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "\n",
    "# 构造训练集\n",
    "X = np.random.randn(100, 2)\n",
    "w_true = np.array([3, 5])\n",
    "y = X.dot(w_true) + np.random.randn(100)\n",
    "\n",
    "# 创建贝叶斯模型\n",
    "with pm.Model() as model:\n",
    "    # 定义参数的先验分布\n",
    "    w = pm.Normal('w', mu=0, sd=1, shape=2)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    # 定义输出标签的条件分布\n",
    "    y_obs = pm.Normal('y_obs', mu=pm.math.dot(X, w), sd=sigma, observed=y)\n",
    "    \n",
    "    # 进行后验推断\n",
    "    trace = pm.sample(1000, tune=1000)\n",
    "\n",
    "# 输出参数估计结果\n",
    "print(\"参数估计结果：\")\n",
    "print(pm.summary(trace)['mean'])\n",
    "\n",
    "# 进行预测\n",
    "x_new = np.array([[1, 2], [3, 4]])  # 新的输入特征\n",
    "with model:\n",
    "    post_pred = pm.sample_posterior_predictive(trace, samples=1000, vars=[y_obs])\n",
    "    y_pred_mean = np.mean(post_pred['y_obs'], axis=0)\n",
    "\n",
    "print(\"预测结果：\")\n",
    "print(y_pred_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082712b",
   "metadata": {},
   "source": [
    "### 贝叶斯岭回归\n",
    "\n",
    "贝叶斯岭回归（Bayesian Ridge Regression）是一种基于贝叶斯统计推断的回归方法，结合了岭回归和贝叶斯推断的思想。它通过引入先验分布来表达参数的不确定性，并利用观测数据来更新参数的后验分布。\n",
    "\n",
    "在贝叶斯岭回归中，我们将回归系数视为随机变量，并假设其服从高斯分布的先验分布，即 $w ∝ N(0, α^{-1}I)$，其中 $w$ 是回归系数向量，$α$ 是超参数，$I$ 是单位矩阵。\n",
    "\n",
    "同时，我们还假设输出变量y也服从高斯分布，即 $ y ∝ N(Xw, σ^2I) $，其中 $X$ 是输入特征矩阵，$σ^2$ 是噪声方差。\n",
    "\n",
    "根据贝叶斯定理，我们可以计算出参数的后验分布。对于贝叶斯岭回归而言，参数的后验分布是一个高斯分布，即 $p(w|X, y) ∝ N(w_{hat}, V_{hat})$，其中$w_hat$是参数的后验均值， $V_hat$ 是参数的后验协方差矩阵。\n",
    "\n",
    "贝叶斯岭回归的参数估计和预测与传统岭回归类似，但在引入先验分布时考虑了参数的不确定性。通过参数的后验分布，我们可以获得更全面的参数估计和预测结果，并能够量化预测的不确定性。\n",
    "\n",
    "下面是使用Python和Scikit-learn库实现贝叶斯岭回归的示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3592154",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47d045d2b9df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 创建贝叶斯岭回归模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbayesian_ridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# 创建贝叶斯岭回归模型\n",
    "bayesian_ridge = BayesianRidge()\n",
    "\n",
    "# 拟合模型\n",
    "bayesian_ridge.fit(X, y)\n",
    "\n",
    "# 输出参数估计结果\n",
    "print(\"参数估计结果：\")\n",
    "print(bayesian_ridge.coef_)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = bayesian_ridge.predict(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
