{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab0ad6e",
   "metadata": {},
   "source": [
    "## logistic \n",
    "\n",
    "逻辑回归（Logistic Regression）是一种广泛应用于分类问题的统计学习方法。它基于线性回归模型，通过一个非线性的逻辑函数（称为“sigmoid函数”或“逻辑函数”）将预测结果映射到概率值，从而对样本进行分类。\n",
    "\n",
    "在逻辑回归中，我们假设输入特征X与输出标签 $Y$ 之间存在一种概率关系，并希望根据特征来预测属于某个类别的概率。逻辑回归可以处理二分类问题，也可以通过扩展为多分类问题。\n",
    "\n",
    "具体而言，逻辑回归的数学模型如下：\n",
    "\n",
    "* 假设函数（Hypothesis Function）： \n",
    "\n",
    "$hθ(x) = g(θ^T x)$ \n",
    "\n",
    "其中 \n",
    "\n",
    "$g(z) = \\frac{1}{1 + e^{-z}} $ \n",
    "\n",
    "是逻辑函数。\n",
    "\n",
    "* 损失函数（Loss Function）：\n",
    "\n",
    "对于二分类问题，使用对数损失函数（Log Loss）：\n",
    "\n",
    "$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\theta(x^{(i)})) + (1-y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))] $\n",
    "\n",
    "其中 $m$ 是样本数量，$y$是实际标签。\n",
    "\n",
    "* 参数估计：\n",
    "\n",
    "使用梯度下降等优化算法最小化损失函数 $J(θ)$，得到参数θ的估计值。\n",
    "\n",
    "* 预测：\n",
    "\n",
    "根据学习到的参数 $θ$，对新样本进行预测，即计算 $hθ(x)$ 的概率值，并根据阈值进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93290d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (100, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/xue/work/code/github/introduction-to-machine-learning/docs/回归/逻辑回归.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xue/work/code/github/introduction-to-machine-learning/docs/%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m logistic_reg \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xue/work/code/github/introduction-to-machine-learning/docs/%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# 拟合模型\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xue/work/code/github/introduction-to-machine-learning/docs/%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m logistic_reg\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xue/work/code/github/introduction-to-machine-learning/docs/%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# 输出参数估计结果\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xue/work/code/github/introduction-to-machine-learning/docs/%E5%9B%9E%E5%BD%92/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m参数估计结果：\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tool/anaconda3/envs/data-explore/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/tool/anaconda3/envs/data-explore/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1206\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1208\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1209\u001b[0m     X,\n\u001b[1;32m   1210\u001b[0m     y,\n\u001b[1;32m   1211\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1212\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1213\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1214\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1215\u001b[0m )\n\u001b[1;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/tool/anaconda3/envs/data-explore/lib/python3.11/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/tool/anaconda3/envs/data-explore/lib/python3.11/site-packages/sklearn/utils/validation.py:1162\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[1;32m   1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1166\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/tool/anaconda3/envs/data-explore/lib/python3.11/site-packages/sklearn/utils/validation.py:1183\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1183\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1184\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, estimator_name\u001b[39m=\u001b[39mestimator_name)\n\u001b[1;32m   1185\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m~/tool/anaconda3/envs/data-explore/lib/python3.11/site-packages/sklearn/utils/validation.py:1244\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1234\u001b[0m             (\n\u001b[1;32m   1235\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[1;32m   1242\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_order(xp\u001b[39m.\u001b[39mreshape(y, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,)), order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, xp\u001b[39m=\u001b[39mxp)\n\u001b[0;32m-> 1244\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1245\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[1;32m   1246\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (100, 5) instead."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# 生成样本数据\n",
    "np.random.seed(0)\n",
    "n_samples, n_features = 100, 10\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.random.randn(n_samples)  # 生成5个相关联的目标变量\n",
    "\n",
    "# 创建逻辑回归模型\n",
    "logistic_reg = LogisticRegression()\n",
    "\n",
    "# 拟合模型\n",
    "logistic_reg.fit(X, y)\n",
    "\n",
    "# 输出参数估计结果\n",
    "print(\"参数估计结果：\")\n",
    "print(logistic_reg.coef_)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = logistic_reg.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
